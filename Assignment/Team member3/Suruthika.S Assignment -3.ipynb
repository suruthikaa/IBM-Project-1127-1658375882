{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB3JfJ8bkRQj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnf7sc6xkT7H"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ4_Jl4BKoVC",
        "outputId": "cc24b8ee-8ebc-4552-be74-d340317213ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 457 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "xtrain = train_datagen.flow_from_directory('flowers', target_size=(64,64),class_mode='binary',batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0vr3kLGkx5s",
        "outputId": "e122f8d3-8412-401f-c3c8-0aeac88b1648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 457 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "xtest = train_datagen.flow_from_directory('flowers',target_size=(64,64),class_mode='binary',batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5S_wlNvl8tt"
      },
      "outputs": [],
      "source": [
        "#cnn model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuRHEA6OmDKs"
      },
      "outputs": [],
      "source": [
        "#Adding the layers\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(300,activation='relu'))\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dense(5,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXIbK_ddmG0-"
      },
      "outputs": [],
      "source": [
        "#model compilation\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jgi_HqBmLKJ"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noO3pC-ymRvv"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy',patience=5)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',patience=5,factor=0.5,min_lr=0.00001)\n",
        "callback = [reduce_lr,early_stopping]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(xtrain,steps_per_epoch=len(xtrain),epochs=10,validation_data=xtest,validation_steps=len(xtest))"
      ],
      "metadata": {
        "id": "XLlkyDGSfeVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmLsRpBmmdgw"
      },
      "outputs": [],
      "source": [
        "#saving the model\n",
        "model.save('Flower.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlBeC0hxmjfd"
      },
      "outputs": [],
      "source": [
        "#testing the model\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAllo_swmq9l"
      },
      "outputs": [],
      "source": [
        "img = image.load_img('/content/flowers/daisy/100080576_f52e8ee070_n.jpg',target_size=(64,64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEscB6xUmr12",
        "outputId": "67f8cd77-a06a-49fc-9d91-f9d7f9ee4f51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[141., 141., 139.],\n",
              "        [149., 149., 149.],\n",
              "        [152., 152., 154.],\n",
              "        ...,\n",
              "        [162., 161., 166.],\n",
              "        [154., 154., 152.],\n",
              "        [153., 153., 153.]],\n",
              "\n",
              "       [[136., 135., 131.],\n",
              "        [146., 145., 143.],\n",
              "        [169., 168., 174.],\n",
              "        ...,\n",
              "        [159., 158., 163.],\n",
              "        [155., 155., 153.],\n",
              "        [149., 149., 149.]],\n",
              "\n",
              "       [[125., 125., 117.],\n",
              "        [138., 140., 137.],\n",
              "        [152., 152., 152.],\n",
              "        ...,\n",
              "        [156., 156., 156.],\n",
              "        [157., 157., 155.],\n",
              "        [143., 142., 140.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 41.,  44.,  23.],\n",
              "        [ 43.,  46.,  25.],\n",
              "        [ 49.,  51.,  37.],\n",
              "        ...,\n",
              "        [128., 124., 121.],\n",
              "        [125., 121., 118.],\n",
              "        [125., 122., 117.]],\n",
              "\n",
              "       [[ 43.,  46.,  25.],\n",
              "        [ 43.,  46.,  25.],\n",
              "        [ 54.,  55.,  37.],\n",
              "        ...,\n",
              "        [130., 126., 125.],\n",
              "        [129., 125., 124.],\n",
              "        [127., 123., 122.]],\n",
              "\n",
              "       [[ 44.,  47.,  26.],\n",
              "        [ 45.,  48.,  27.],\n",
              "        [ 53.,  55.,  34.],\n",
              "        ...,\n",
              "        [137., 133., 132.],\n",
              "        [133., 129., 128.],\n",
              "        [130., 126., 125.]]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = image.img_to_array(img)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x)"
      ],
      "metadata": {
        "id": "ttXmk7a0fki1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY3AjHS8n_bX"
      },
      "outputs": [],
      "source": [
        "output = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "pred = np.argmax(model.predict(x))\n",
        "output[pred]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('flowers/rose/10894627425_ec76bbc757_n.jpg',target_size=(64,64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "pred = np.argmax(model.predict(x))\n",
        "output[pred]"
      ],
      "metadata": {
        "id": "3ycn2HgzfsAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI6DBMveoHUI"
      },
      "outputs": [],
      "source": [
        "img = image.load_img('flowers/dandelion/16041975_2f6c1596e5.jpg',target_size=(64,64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "pred = np.argmax(model.predict(x))\n",
        "output[pred]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}